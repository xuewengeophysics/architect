# 基于规约树的CUDA编程

## 1. 介绍

### 1.1 规约

+ 规约：**规约是一类并行算法**，对传入的N个数据，**使用一个二元的符合结合律的操作符⊕，生成1个结果**。这类操作包括取最小、取最大、求和、平方和、逻辑与/或、向量点积。

+ 规约也是其他高级算法中重要的基础算法对于N个输入数据和操作符+，规约可表示为：

  ![image-20201216093752442](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216093752442.png)  

### 1.2 规约和

#### 1.2.1 两遍规约

+ 假设共享内存的大小等于线程块的线程数量，在启动的时候指定。同时要注意，该内核块的线程数量必须是2的幂次。

![image-20201216094407303](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216094407303.png)  



+ **块内合并数据时线程数每次减少一半**：

![image-20201216094444101](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216094444101.png) 

#### 1.2.2 两遍规约的线程束优化

+ CUDA会把线程组成**线程束warp(目前是32个线程)**，warp的执行由**SIMD(单指令多数据流)**硬件完成，每个线程块中的线程束是按照**锁步方式(lockstep)**执行每条指令的，因此当线程块中活动线程数低于硬件线程束的大小时，可以无须再调用__syncthreads()来同步。**因为阻塞的方式同步等待耗时**。

+ 不过需要注意，编写线程束同步代码时，**必须对共享内存的指针使用volatile关键字修饰**，否则可能会由于编译器的优化行为改变内存的操作顺序从而使结果不正确。

![image-20201216102610004](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216102610004.png) 

#### 1.2.3 任意线程块大小的规约

+ 前面的内核块的线程数量**必须是2的幂次**，否则计算结果是不正确的，下面把它修改成适应任意大小的数据。其实只需在循环之前把待规约的数组(shared memory 中的sPartials)调整成2的幂次即可。

+ 步骤和之前一样：

1. **先申请共享内存sPartials[]**，把所有的原始都读到共享内存内；
2. 然后进行同步，**把所有的线程同步**；
3. **把超过2^n次的数据加到前面去，调整成2的N次幂**：

![image-20201216103641317](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216103641317.png)  

![image-20201216095120208](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216095120208.png)  

+ 类似于向下取整，对于非`2^n`长度的数组(L)，取小于L的最大的`2^n`的数(floorPow2)，把后面的是数据使用⊕操作把中间结果保存在`index-floorPow2`中，其中index是数据原来的索引。当`N & (N - 1)=0`时，N为2的幂次，否则继续计算 `N &= (N - 1)`，直到`N & (N - 1)=0`，此时N即为floorPow2。

#### 1.2.4 基于原子操作的单遍规约

+ 上面的代码需要**启动两次内核**，当然，由于CPU和GPU是异步执行，其实效率也是很高的。下面来介绍单遍规约，两遍规约的做法主要针对CUDA线程块无法同步这一问题的解决方法，使用原子操作和共享内存的组合可以避免第二个内核的调用。
+ 如果硬件支持操作符⊕的原子操作，那么单遍规约操作就可以变得很简单，比如对于加法操作，只需调用atomicAdd()把块中的部分结果加到全局内存中即可

![image-20201216095156001](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216095156001.png)  

#### 1.2.5 基于原子操作的单遍规约的优化

+ 为了**减少全局内存的写操作和原子操作的竞争**，可以进行一些优化，在块中先进行规约操作得到部分结果，再把这个部分结果使用原子操作加到全局内存中，这样每个块只需一次全局内存写操作和原子操作。

![image-20201216095258119](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216095258119.png)  

#### 1.2.6 非原子操作的单遍规约

+ 对于不支持原子操作的单遍规约就要复杂一些，需要使用一个设备内存（全局内存）位置跟踪哪个线程块已经写完了自己的部分，一旦所有的块都完成后，使用一个快进行最后的规约，将结果写回。

+ 由于需要多次执行对共享内存的数据进行规约，因此把上面的规约代码单独提取出来作为一个设备函数，以便重用。reduction3_logStepShared()函数，对来自共享内存的sPartials执行规约操作，规约结果写会由out指定的内存，代码如下（这段代码也可以使用模板展开for循环）：

```
__device__ void reduction3_logStepShared(int *out, volatile int *sPartials)
{
    const int tid = threadIdx.x;
    int floorPow2 = blockDim.x;

    if (floorPow2 & (floorPow2 - 1))
    {
        while (floorPow2 & (floorPow2 - 1))
        {
            floorPow2 &= (floorPow2 - 1);
        }
        if (tid >= floorPow2)
        {
            sPartials[tid - floorPow2] += sPartials[tid];
        }
        __syncthreads();
    }

    for (int activeTrheads = floorPow2 / 2; activeTrheads > 32; activeTrheads /= 2)
    {
        if (tid < activeTrheads)
        {
            sPartials[tid] += sPartials[tid + activeTrheads];
        }
        __syncthreads();
    }

    if (tid < 32)
    {
        if (floorPow2 > 32) sPartials[tid] += sPartials[tid + 32];
        if (floorPow2 > 16) sPartials[tid] += sPartials[tid + 16];
        if (floorPow2 > 8) sPartials[tid] += sPartials[8];
        if (floorPow2 > 4) sPartials[tid] += sPartials[4];
        if (floorPow2 > 2) sPartials[tid] += sPartials[2];
        if (floorPow2 > 1) sPartials[tid] += sPartials[1];

        if (tid == 0)
        {
            *out = sPartials[0];
        }
    }
}
```

+ 单遍规约代码如下：

```
__device__ unsigned int retirementCount = 0;
__global__ void reduction3_kernel(int *out, int *partial, const int *in, size_t N)
{
    extern __shared__ int sPartials[];
    const int tid = threadIdx.x;
    int sum = 0;

    for (size_t i = blockIdx.x * blockDim.x + tid; i < N; i += blockDim.x * gridDim.x)
    {
        sum += in[i];
    }
    sPartials[tid] = sum;
    __syncthreads();

    if (gridDim.x == 1)
    {
        reduction3_logStepShared(out, sPartials);
        return;
    }
    reduction3_logStepShared(&partial[blockIdx.x], sPartials);

    __shared__ bool lastBlock;
    __threadfence();

    if (tid == 0)
    {
        unsigned int ticket = atomicAdd(&retirementCount, 1);
        lastBlock = (ticket == gridDim.x - 1);
    }

    __syncthreads();

    if (lastBlock)
    {
        sum = 0;
        for (size_t i = tid; i < gridDim.x; i += blockDim.x)
        {
            sum += partial[i];
        }
        sPartials[tid] = sum;
        __syncthreads();

        reduction3_logStepShared(out, sPartials);
        retirementCount_1 = 0;
    }
}

void reduction3(int *answer, int *partial, const int *in, const size_t N, const int numBlocks, int numThreads)
{
    unsigned int sharedSize = numThreads * sizeof(int);
    reduction3_kernel<<<numBlocks, numThreads, sharedSize>>>(answer, partial, in, N);
}
```

+ 和前面的规约代码类似，内核首先计算部分规约并将结果写入共享内存。一旦完成上述操作，接下来需要分两种情况讨论：1个Block和多个Block：
  + 1个Block时不存在Block间同步的问题，直接调用reduction3_logStepShared()就得到了最终规约结果。
  + 多个Block时情况要复杂，由于Block间无法直接通信，使用一个全局内存上的变量retirementCount来记录线程块的执行情况，每个Block的0号线程调用atomicAdd()函数对retirementCount进行加1操作，atomicAdd()会返回操作前的值，最后一个Block会把lastBlock设为真，在最后一个线程块中对所有块的部分规约结果再次规约，得到最终规约结果。

+ 该内核代码调用了__threadfence()函数，该函数会导致所有的块都等待，直到任何挂起的内存事务已写回到设备内存。当__threadfence()执行时，写入全局内存的操作不仅仅可见于被调用线程或者线程块，而是所有线程。



## 2. 拓展：CUDA并行算法系列之规约

+ 串行实现完成计算需要7步，性能比较差；
+ 成对的方式是典型的分治思想，只需要lgN步来计算结果，由于不能合并内存事务，这种实现在CUDA中性能较差；
+ 在CUDA中，无论是对全局内存还是共享内存，基于交替策略效果更好。对于全局内存，使用blockDim.x*gridDim.x的倍数作为交替因子有良好的性能，因为**所有的内存事务将被合并**。对于共享内存，最好的性能是按照所确定的交错因子来累计部分结果，以避免存储片冲突，并保持线程块的相邻线程处于活跃状态。

![image-20201216111951110](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20201216111951110.png)  



## 3. 参考资料

1. [CUDA并行算法系列之规约](https://www.cnblogs.com/5long/p/algorithms-on-cuda-reduction.html)